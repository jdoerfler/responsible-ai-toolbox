
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>rai_toolbox.mushin.lightning.launchers &#8212; rai-toolbox  documentation</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/tabs.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
    <script src="../../../../_static/jquery.js"></script>
    <script src="../../../../_static/underscore.js"></script>
    <script src="../../../../_static/doctools.js"></script>
    <script src="../../../../_static/clipboard.min.js"></script>
    <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/tabs.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
    
    <div class="container-fluid" id="banner"></div>

    
    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    
<a class="navbar-brand" href="../../../../index.html">
<p class="title">rai-toolbox</p>
</a>

    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../tutorials.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../how_tos.html">
  How-To Guides
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../explanation.html">
  Explanation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../api_reference.html">
  Reference
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="../../../../changes.html">
  Changelog
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/mit-ll-responsible-ai/responsible-ai-toolbox" rel="noopener" target="_blank" title="GitHub"><span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label></a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    

    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items"><form class="bd-search d-flex align-items-center" action="../../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <h1>Source code for rai_toolbox.mushin.lightning.launchers</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2022, MASSACHUSETTS INSTITUTE OF TECHNOLOGY</span>
<span class="c1"># Subject to FAR 52.227-11 – Patent Rights – Ownership by the Contractor (May 2014).</span>
<span class="c1"># SPDX-License-Identifier: MIT</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">subprocess</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">sleep</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Optional</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">hydra.core.hydra_config</span> <span class="kn">import</span> <span class="n">HydraConfig</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning</span> <span class="kn">import</span> <span class="n">Trainer</span>
<span class="kn">from</span> <span class="nn">pytorch_lightning.trainer.states</span> <span class="kn">import</span> <span class="n">TrainerFn</span>

<span class="kn">from</span> <span class="nn">.._compatibility</span> <span class="kn">import</span> <span class="n">PL_VERSION</span><span class="p">,</span> <span class="n">Version</span>

<span class="k">if</span> <span class="n">PL_VERSION</span> <span class="o">&gt;=</span> <span class="n">Version</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
    <span class="kn">from</span> <span class="nn">pytorch_lightning.strategies.ddp</span> <span class="kn">import</span> <span class="n">DDPStrategy</span>
    <span class="kn">from</span> <span class="nn">pytorch_lightning.strategies.launchers.subprocess_script</span> <span class="kn">import</span> <span class="p">(</span>
        <span class="n">_SubprocessScriptLauncher</span><span class="p">,</span>
    <span class="p">)</span>

<span class="k">else</span><span class="p">:</span>  <span class="c1"># pragma: no cover</span>
    <span class="kn">from</span> <span class="nn">pytorch_lightning.plugins.training_type.ddp</span> <span class="kn">import</span> <span class="n">DDPPlugin</span>


<span class="k">def</span> <span class="nf">_setup_environment</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">is_initialized</span><span class="p">():</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">destroy_process_group</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_teardown</span><span class="p">():</span>
    <span class="c1"># Remove PL environments so next multirun starts fresh</span>
    <span class="n">envs</span> <span class="o">=</span> <span class="p">(</span>
        <span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">,</span>
        <span class="s2">&quot;NODE_RANK&quot;</span><span class="p">,</span>
        <span class="s2">&quot;WORLD_SIZE&quot;</span><span class="p">,</span>
        <span class="s2">&quot;MASTER_ADDR&quot;</span><span class="p">,</span>
        <span class="s2">&quot;MASTER_PORT&quot;</span><span class="p">,</span>
        <span class="s2">&quot;PL_GLOBAL_SEED&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">envs</span><span class="p">:</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>


<span class="k">if</span> <span class="n">PL_VERSION</span> <span class="o">&gt;=</span> <span class="n">Version</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>

    <span class="k">class</span> <span class="nc">HydraDDP</span><span class="p">(</span><span class="n">DDPStrategy</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;DDP Strategy that supports Hydra run and multirun jobs.</span>

<span class="sd">        This strategy assumes a `Trainer.fit` or `Trainer.test` has been configured</span>
<span class="sd">        to execute via Hydra.  It requires that Hydra saves a `config.yaml` in the current</span>
<span class="sd">        working directory with the following keys/properties set:</span>

<span class="sd">            trainer: A `pytorch_lightning.Trainer` configuration</span>
<span class="sd">            module: A `pytorch_lightning.LightningModule` configuration</span>
<span class="sd">            pl_testing: A boolean: True for `Trainer.test` and False (default) `Trainer.fit`</span>

<span class="sd">        This strategy will launch a child subprocesses for additional GPU beyond the first using</span>
<span class="sd">        the following base command:</span>

<span class="sd">        ```</span>
<span class="sd">        python -m rai_toolbox.mushin.lightning._pl_main -cp &lt;path to config.yaml&gt; -cn config.yaml</span>
<span class="sd">        ```</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        In order to execute a MULTIRUN Hydra job we must make sure to destroy an distributed</span>
<span class="sd">        processes on setup of this function.  This will lead to issues if running multiple jobs</span>
<span class="sd">        in the notebook or trying to do `Trainer.fit` followed by `Trainer.test`.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt; trainer = Trainer(Trainer, accelerator=&quot;auto&quot;, devices=2, strategy=builds(HydraDDP))</span>
<span class="sd">        &gt;&gt; trainer.fit(module)</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">setup_environment</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_setup_environment</span><span class="p">()</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">setup_environment</span><span class="p">()</span>

        <span class="k">def</span> <span class="nf">_configure_launcher</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">creates_processes_externally</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_launcher</span> <span class="o">=</span> <span class="n">HydraDDPLauncher</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_processes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_rank_0_will_call_children_scripts</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">def</span> <span class="nf">teardown</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
            <span class="sd">&quot;&quot;&quot;Performs additional teardown steps for PL to allow for Hydra multirun jobs.&quot;&quot;&quot;</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">teardown</span><span class="p">()</span>
            <span class="n">_teardown</span><span class="p">()</span>

    <span class="k">class</span> <span class="nc">HydraDDPLauncher</span><span class="p">(</span><span class="n">_SubprocessScriptLauncher</span><span class="p">):</span>
        <span class="k">def</span> <span class="nf">launch</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">,</span>
            <span class="n">function</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
            <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
            <span class="n">trainer</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="s2">&quot;Trainer&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
            <span class="sd">&quot;&quot;&quot;Creates new processes, then calls the given function.</span>

<span class="sd">            Arguments:</span>
<span class="sd">                function: A callback function to execute after all processes have been created.</span>
<span class="sd">                    It is up to the implementation of this function to synchronize the processes, e.g., with barriers.</span>
<span class="sd">                *args: Optional positional arguments to be passed to the given function.</span>
<span class="sd">                trainer: Optional reference to the :class:`~pytorch_lightning.trainer.trainer.Trainer`.</span>
<span class="sd">                **kwargs: Optional keyword arguments to be passed to the given function.</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">creates_processes_externally</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_call_children_scripts</span><span class="p">(</span><span class="n">trainer</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">_call_children_scripts</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">trainer</span><span class="p">):</span>
            <span class="c1"># bookkeeping of spawned processes</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_can_spawn_children</span><span class="p">()</span>

            <span class="c1"># DDP Environment variables</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MASTER_ADDR&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">main_address</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MASTER_PORT&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">main_port</span><span class="p">)</span>

            <span class="c1"># allow the user to pass the node rank</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;NODE_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">node_rank</span><span class="p">())</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">local_rank</span><span class="p">())</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;WORLD_SIZE&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_processes</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">}</span><span class="s2">&quot;</span>

            <span class="k">for</span> <span class="n">local_rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_processes</span><span class="p">):</span>
                <span class="n">env_copy</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">env_copy</span><span class="p">[</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&quot;</span>

                <span class="c1"># CWD is the Hydra working directory</span>
                <span class="n">cwd</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
                <span class="n">os_cwd</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;&quot;</span><span class="si">{</span><span class="n">cwd</span><span class="si">}</span><span class="s1">&quot;&#39;</span>  <span class="c1"># this is needed to handle characters like `=` in the directory name</span>

                <span class="n">command</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">sys</span><span class="o">.</span><span class="n">executable</span><span class="p">,</span>
                    <span class="s2">&quot;-m&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;rai_toolbox.mushin.lightning._pl_main&quot;</span><span class="p">,</span>
                <span class="p">]</span>
                <span class="n">hydra_cfg</span> <span class="o">=</span> <span class="n">HydraConfig</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
                <span class="n">hydra_output</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cwd</span><span class="p">,</span> <span class="n">hydra_cfg</span><span class="o">.</span><span class="n">output_subdir</span><span class="p">)</span>

                <span class="c1"># create the command for CLI</span>
                <span class="n">command</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;-cp&quot;</span><span class="p">,</span> <span class="n">hydra_output</span><span class="p">,</span> <span class="s2">&quot;-cn&quot;</span><span class="p">,</span> <span class="s2">&quot;config.yaml&quot;</span><span class="p">]</span>

                <span class="c1"># TODO: See about having PL fix this behavior so we know</span>
                <span class="c1"># which function is being called</span>
                <span class="c1"># trainer_fn = trainer.state.fn</span>
                <span class="c1"># if trainer_fn == TrainerFn.FITTING:</span>
                <span class="c1">#     command += [&quot;+_ddp_testing=false&quot;]</span>
                <span class="c1"># else:</span>
                <span class="c1">#     command += [&quot;+_ddp_testing=true&quot;]</span>

                <span class="n">command</span> <span class="o">+=</span> <span class="p">[</span>
                    <span class="sa">f</span><span class="s2">&quot;hydra.output_subdir=.pl_hydra_</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;hydra.run.dir=</span><span class="si">{</span><span class="n">os_cwd</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;hydra.job.name=train_ddp_process_</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="p">]</span>
                <span class="n">subprocess</span><span class="o">.</span><span class="n">Popen</span><span class="p">(</span><span class="n">command</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env_copy</span><span class="p">,</span> <span class="n">cwd</span><span class="o">=</span><span class="n">cwd</span><span class="p">)</span>

                <span class="c1"># starting all processes at once can cause issues</span>
                <span class="c1"># with dataloaders delay between 1-10 seconds</span>
                <span class="n">delay</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">sleep</span><span class="p">(</span><span class="n">delay</span><span class="p">)</span>

<span class="k">else</span><span class="p">:</span>  <span class="c1"># pragma: no cover</span>

<div class="viewcode-block" id="HydraDDP"><a class="viewcode-back" href="../../../../generated/rai_toolbox.mushin.HydraDDP.html#rai_toolbox.mushin.HydraDDP">[docs]</a>    <span class="k">class</span> <span class="nc">HydraDDP</span><span class="p">(</span><span class="n">DDPPlugin</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;DDP plugin that supports Hydra run and multirun jobs.</span>

<span class="sd">        This plugin assumes a `Trainer.fit` or `Trainer.test` has been configured</span>
<span class="sd">        to execute via Hydra.  It requires that Hydra saves a `config.yaml` in the current</span>
<span class="sd">        working directory with the following keys/properties set:</span>

<span class="sd">            trainer: A `pytorch_lightning.Trainer` configuration</span>
<span class="sd">            module: A `pytorch_lightning.LightningModule` configuration</span>

<span class="sd">        This plugin will launch a child subprocesses for additional GPU beyond the first using</span>
<span class="sd">        the following base command:</span>

<span class="sd">        ```</span>
<span class="sd">        python -m rai_toolbox.mushin.lightning._pl_main -cp &lt;path to config.yaml&gt; -cn config.yaml</span>
<span class="sd">        ```</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        In order to execute a MULTIRUN Hydra job we must make sure to destroy an distributed</span>
<span class="sd">        processes on setup of this function.  This will lead to issues if running multiple jobs</span>
<span class="sd">        in the notebook or trying to do `Trainer.fit` followed by `Trainer.test`.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt; trainer = Trainer(Trainer, accelerator=&quot;auto&quot;, devices=2, strategy=builds(HydraDDP))</span>
<span class="sd">        &gt;&gt; trainer.fit(module)</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">setup_environment</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_setup_environment</span><span class="p">()</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">setup_environment</span><span class="p">()</span>

        <span class="k">def</span> <span class="nf">_call_children_scripts</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="c1"># bookkeeping of spawned processes</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_check_can_spawn_children</span><span class="p">()</span>

            <span class="c1"># DDP Environment variables</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MASTER_ADDR&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">master_address</span><span class="p">()</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;MASTER_PORT&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">master_port</span><span class="p">())</span>

            <span class="c1"># allow the user to pass the node rank</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;NODE_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">node_rank</span><span class="p">())</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cluster_environment</span><span class="o">.</span><span class="n">local_rank</span><span class="p">())</span>
            <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;WORLD_SIZE&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">num_processes</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_nodes</span><span class="si">}</span><span class="s2">&quot;</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">interactive_ddp_procs</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">local_rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_processes</span><span class="p">):</span>
                <span class="n">env_copy</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
                <span class="n">env_copy</span><span class="p">[</span><span class="s2">&quot;LOCAL_RANK&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&quot;</span>

                <span class="c1"># CWD is the Hydra working directory</span>
                <span class="n">cwd</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
                <span class="n">os_cwd</span> <span class="o">=</span> <span class="sa">f</span><span class="s1">&#39;&quot;</span><span class="si">{</span><span class="n">cwd</span><span class="si">}</span><span class="s1">&quot;&#39;</span>  <span class="c1"># this is needed to handle characters like `=` in the directory name</span>

                <span class="n">trainer_fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lightning_module</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="o">.</span><span class="n">fn</span>
                <span class="n">command</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">sys</span><span class="o">.</span><span class="n">executable</span><span class="p">,</span>
                    <span class="s2">&quot;-m&quot;</span><span class="p">,</span>
                    <span class="s2">&quot;rai_toolbox.mushin.lightning._pl_main&quot;</span><span class="p">,</span>
                <span class="p">]</span>
                <span class="n">hydra_cfg</span> <span class="o">=</span> <span class="n">HydraConfig</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
                <span class="n">hydra_output</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cwd</span><span class="p">,</span> <span class="n">hydra_cfg</span><span class="o">.</span><span class="n">output_subdir</span><span class="p">)</span>

                <span class="c1"># create the command for CLI</span>
                <span class="n">command</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;-cp&quot;</span><span class="p">,</span> <span class="n">hydra_output</span><span class="p">,</span> <span class="s2">&quot;-cn&quot;</span><span class="p">,</span> <span class="s2">&quot;config.yaml&quot;</span><span class="p">]</span>

                <span class="k">if</span> <span class="n">trainer_fn</span> <span class="o">==</span> <span class="n">TrainerFn</span><span class="o">.</span><span class="n">FITTING</span><span class="p">:</span>
                    <span class="n">command</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;+pl_testing=false&quot;</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">command</span> <span class="o">+=</span> <span class="p">[</span><span class="s2">&quot;+pl_testing=true&quot;</span><span class="p">]</span>

                <span class="n">command</span> <span class="o">+=</span> <span class="p">[</span>
                    <span class="sa">f</span><span class="s2">&quot;hydra.output_subdir=.pl_hydra_</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;hydra.run.dir=</span><span class="si">{</span><span class="n">os_cwd</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;hydra.job.name=train_ddp_process_</span><span class="si">{</span><span class="n">local_rank</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="p">]</span>
                <span class="n">proc</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">Popen</span><span class="p">(</span><span class="n">command</span><span class="p">,</span> <span class="n">env</span><span class="o">=</span><span class="n">env_copy</span><span class="p">,</span> <span class="n">cwd</span><span class="o">=</span><span class="n">cwd</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">interactive_ddp_procs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">proc</span><span class="p">)</span>

                <span class="c1"># starting all processes at once can cause issues</span>
                <span class="c1"># with dataloaders delay between 1-10 seconds</span>
                <span class="n">delay</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">sleep</span><span class="p">(</span><span class="n">delay</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_rank_0_has_called_call_children_scripts</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">def</span> <span class="nf">teardown</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
            <span class="sd">&quot;&quot;&quot;Performs additional teardown steps for PL to allow for Hydra multirun jobs.&quot;&quot;&quot;</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">teardown</span><span class="p">()</span>
            <span class="n">_teardown</span><span class="p">()</span></div>
</pre></div>

              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
</div>
              
          </main>
          

      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2022 Massachusetts Institute of Technology.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.5.0.<br>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>